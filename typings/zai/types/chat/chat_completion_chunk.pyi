"""
This type stub file was generated by pyright.
"""

from typing import Any, Dict, List, Optional
from zai.core import BaseModel

class ChoiceDeltaFunctionCall(BaseModel):
	"""
	Function call delta information in streaming response

	Attributes:
		arguments: Function call arguments
		name: Function name
	"""
	arguments: Optional[str] = ...
	name: Optional[str] = ...


class ChoiceDeltaToolCallFunction(BaseModel):
	"""
	Tool call function delta information in streaming response

	Attributes:
		arguments: Function call arguments
		name: Function name
	"""
	arguments: Optional[str] = ...
	name: Optional[str] = ...


class ChoiceDeltaToolCall(BaseModel):
	"""
	Tool call delta information in streaming response

	Attributes:
		index: Index of the tool call
		id: Unique identifier for the tool call
		function: Function call information
		type: Type of the tool call
	"""
	index: int
	id: Optional[str] = ...
	function: Optional[ChoiceDeltaToolCallFunction] = ...
	type: Optional[str] = ...


class AudioCompletionChunk(BaseModel):
	"""
	Audio completion chunk information

	Attributes:
		id: Unique identifier for the audio chunk
		data: Audio data content
		expires_at: Timestamp when the audio expires
	"""
	id: Optional[str] = ...
	data: Optional[str] = ...
	expires_at: Optional[int] = ...


class ChoiceDelta(BaseModel):
	"""
	Delta information for streaming chat completion choice

	Attributes:
		content: Content delta
		role: Role of the message sender
		reasoning_content: Reasoning content delta
		tool_calls: List of tool call deltas
		audio: Audio completion chunk
	"""
	content: Optional[str] = ...
	role: Optional[str] = ...
	reasoning_content: Optional[str] = ...
	tool_calls: Optional[List[ChoiceDeltaToolCall]] = ...
	audio: Optional[AudioCompletionChunk] = ...


class Choice(BaseModel):
	"""
	Choice information in streaming chat completion

	Attributes:
		delta: Delta information for the choice
		finish_reason: Reason why the completion finished
		index: Index of the choice
	"""
	delta: ChoiceDelta
	finish_reason: Optional[str] = ...
	index: int


class PromptTokensDetails(BaseModel):
	"""
	Detailed breakdown of token usage for the input prompt

	Attributes:
		cached_tokens: Number of tokens reused from cache
	"""
	cached_tokens: int
	...


class CompletionTokensDetails(BaseModel):
	"""
	Detailed breakdown of token usage for the model completion

	Attributes:
	    reasoning_tokens: Number of tokens used for reasoning steps
	"""
	reasoning_tokens: int
	...


class CompletionUsage(BaseModel):
	"""
	Token usage information for completion

	Attributes:
		prompt_tokens: Number of tokens in the prompt
		completion_tokens: Number of tokens in the completion
		total_tokens: Total number of tokens used
	"""
	prompt_tokens: int
	prompt_tokens_details: Optional[PromptTokensDetails] = ...
	completion_tokens: int
	completion_tokens_details: Optional[CompletionTokensDetails] = ...
	total_tokens: int


class ChatCompletionChunk(BaseModel):
	"""
	Streaming chat completion chunk response

	Attributes:
		id: Unique identifier for the completion
		choices: List of completion choices
		created: Timestamp when the completion was created
		model: Model used for the completion
		usage: Token usage information
		extra_json: Additional JSON data
	"""
	id: Optional[str] = ...
	choices: List[Choice]
	created: Optional[int] = ...
	model: Optional[str] = ...
	usage: Optional[CompletionUsage] = ...
	extra_json: Dict[str, Any]


