"""
This type stub file was generated by pyright.
"""

import httpx
from typing import Dict, List, Optional, TYPE_CHECKING, Union
from typing_extensions import Literal
from zai.core import BaseAPI, Body, Headers, NotGiven, StreamResponse
from zai.types.chat.chat_completion import Completion
from zai.types.chat.chat_completion_chunk import ChatCompletionChunk
from zai.types.chat.code_geex import code_geex_params
from zai.types.sensitive_word_check import SensitiveWordCheckRequest
from zai._client import ZaiClient

logger = ...
if TYPE_CHECKING:
	...
class Completions(BaseAPI):
	"""
	Chat completions API resource

	Attributes:
		client (ZaiClient): The ZAI client instance
	"""
	def __init__(self, client: ZaiClient) -> None:
		...
	
	def create(self, *, model: str, request_id: Optional[str] | NotGiven = ..., user_id: Optional[str] | NotGiven = ..., do_sample: Optional[Literal[False]] | Literal[True] | NotGiven = ..., stream: Optional[Literal[False]] | Literal[True] | NotGiven = ..., temperature: Optional[float] | NotGiven = ..., top_p: Optional[float] | NotGiven = ..., max_tokens: int | NotGiven = ..., seed: int | NotGiven = ..., messages: Union[str, List[str], List[int], object, None], stop: Optional[Union[str, List[str], None]] | NotGiven = ..., sensitive_word_check: Optional[SensitiveWordCheckRequest] | NotGiven = ..., tools: Optional[object] | NotGiven = ..., tool_choice: str | NotGiven = ..., meta: Optional[Dict[str, str]] | NotGiven = ..., extra: Optional[code_geex_params.CodeGeexExtra] | NotGiven = ..., extra_headers: Headers | None = ..., extra_body: Body | None = ..., timeout: float | httpx.Timeout | None | NotGiven = ..., response_format: object | None = ..., thinking: object | None = ..., watermark_enabled: Optional[bool] | NotGiven = ..., tool_stream: bool | NotGiven = ...) -> Completion | StreamResponse[ChatCompletionChunk]:
		"""
		Create a chat completion

		Arguments:
			model (str): Model name to use for completion
			request_id (Optional[str]): Request identifier
			user_id (Optional[str]): User identifier
			do_sample (Optional[bool]): Whether to use sampling
			stream (Optional[bool]): Whether to stream the response
			temperature (Optional[float]): Sampling temperature (0.0, 1.0)
			top_p (Optional[float]): Top-p sampling parameter (0.0, 1.0)
			max_tokens (int): Maximum number of tokens to generate
			seed (int): Random seed for reproducible results
			messages (Union[str, List[str], List[int], object, None]): Input messages
			stop (Optional[Union[str, List[str], None]]): Stop sequences
			sensitive_word_check (Optional[SensitiveWordCheckRequest]): Sensitive word checking configuration
			tools (Optional[object]): Tools available to the model
			tool_choice (str): Tool choice strategy
			meta (Optional[Dict[str, str]]): Additional metadata
			extra (Optional[CodeGeexExtra]): Extra parameters for CodeGeex models
			extra_headers (Headers): Additional HTTP headers
			extra_body (Body): Additional request body parameters
			timeout (float | httpx.Timeout): Request timeout
			response_format (object): Response format specification
			thinking (Optional[object]): Configuration parameters for model reasoning
			watermark_enabled (Optional[bool]): Whether to enable watermark on generated audio
			tool_stream (Optional[bool]): Whether to enable tool streaming
		"""
		...
	


